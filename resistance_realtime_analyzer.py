#!/usr/bin/env python3
"""
=====================================================================
    ANALYSEUR DE R√âSISTANCES EN TEMPS R√âEL
    Projet de Traitement de Signal - EPHEC 2025
=====================================================================

Objectif: Analyser en temps r√©el la valeur d'une r√©sistance via webcam
          ou application smartphone (iVCam, DroidCam, etc.)

Temps de traitement: < 1 seconde par frame (exigence MVP)

Techniques de traitement de signal utilis√©es:
- Filtrage bilat√©ral (pr√©servation des bords)
- √âgalisation adaptative d'histogramme (CLAHE)
- Morphologie math√©matique (ouverture, fermeture)
- Moyenne temporelle pour stabiliser les d√©tections

Auteur: Noah
Date: 2025
=====================================================================
"""

import cv2
import numpy as np
from typing import Tuple, List, Dict, Optional
from collections import deque
from dataclasses import dataclass
import time
from enum import Enum


# =============================================================================
# SECTION 1: STRUCTURES DE DONN√âES
# =============================================================================

@dataclass
class ColorBandInfo:
    """Information sur une bande de couleur d√©tect√©e"""
    color_name: str
    value: int
    x_position: int
    area: int
    height: int
    width: int


@dataclass
class ResistanceReading:
    """Lecture de r√©sistance avec m√©tadonn√©es"""
    value_ohms: float
    formatted_value: str
    tolerance: str
    bands: List[str]
    confidence: float
    timestamp: float


# =============================================================================
# SECTION 2: CONFIGURATION DES COULEURS HSV
# =============================================================================

class HSVColorConfig:
    """
    Configuration des plages HSV pour la d√©tection des couleurs.

    Justification des choix:
    - L'espace HSV s√©pare teinte/saturation/luminosit√©
    - Plus robuste aux variations d'√©clairage que RGB
    - Les plages ont √©t√© calibr√©es pour un fond blanc/uni
    """

    # Format: (H_min, S_min, V_min), (H_max, S_max, V_max), valeur_num√©rique
    COLORS = {
        # Noir: tr√®s faible luminosit√©
        'noir': ([0, 0, 0], [180, 255, 45], 0),

        # Marron: teinte rouge-orange fonc√©
        'marron': ([0, 50, 25], [18, 200, 130], 1),

        # Rouge (partie basse du spectre H)
        'rouge1': ([0, 100, 80], [8, 255, 255], 2),
        # Rouge (partie haute du spectre H - wrap around)
        'rouge2': ([165, 100, 80], [180, 255, 255], 2),

        # Orange
        'orange': ([8, 130, 100], [22, 255, 255], 3),

        # Jaune
        'jaune': ([20, 100, 100], [35, 255, 255], 4),

        # Vert
        'vert': ([35, 50, 50], [80, 255, 255], 5),

        # Bleu
        'bleu': ([85, 50, 50], [125, 255, 255], 6),

        # Violet
        'violet': ([125, 30, 30], [155, 255, 255], 7),

        # Gris: faible saturation
        'gris': ([0, 0, 70], [180, 40, 180], 8),

        # Blanc: tr√®s haute luminosit√©, faible saturation
        'blanc': ([0, 0, 200], [180, 25, 255], 9),

        # Or: jaune-orange m√©tallique sombre
        'or': ([15, 80, 80], [30, 200, 180], -1),

        # Argent: gris brillant
        'argent': ([0, 0, 140], [180, 25, 210], -2),
    }

    @classmethod
    def get_colors(cls) -> Dict:
        """Retourne le dictionnaire des couleurs"""
        return cls.COLORS


# =============================================================================
# SECTION 3: FILTRES DE TRAITEMENT DE SIGNAL
# =============================================================================

class SignalFilters:
    """
    Collection de filtres de traitement de signal pour l'am√©lioration d'image.
    """

    @staticmethod
    def bilateral_filter(image: np.ndarray, d: int = 9,
                         sigma_color: float = 75,
                         sigma_space: float = 75) -> np.ndarray:
        """
        Filtre bilat√©ral: lisse le bruit tout en pr√©servant les bords.

        Principe math√©matique:
        - Combine pond√©ration spatiale (distance) et pond√©ration de similarit√© (intensit√©)
        - I_filtered(x) = Œ£ w_s(x,y) * w_r(I(x),I(y)) * I(y) / normalisation
        - w_s = exp(-|x-y|¬≤/2œÉ_s¬≤) : poids spatial gaussien
        - w_r = exp(-|I(x)-I(y)|¬≤/2œÉ_r¬≤) : poids de similarit√© d'intensit√©

        Avantage pour notre application:
        - Pr√©serve les bords nets entre les bandes de couleur
        - Lisse le bruit dans les zones homog√®nes (fond, corps de r√©sistance)
        """
        return cv2.bilateralFilter(image, d, sigma_color, sigma_space)

    @staticmethod
    def clahe_enhancement(image: np.ndarray,
                          clip_limit: float = 2.0,
                          tile_size: int = 8) -> np.ndarray:
        """
        CLAHE: Contrast Limited Adaptive Histogram Equalization

        Principe:
        1. Divise l'image en tuiles de taille tile_size x tile_size
        2. Calcule l'histogramme de chaque tuile
        3. Limite le contraste (clip_limit) pour √©viter l'amplification du bruit
        4. Redistribue les valeurs en exc√®s
        5. Applique l'√©galisation localement

        Avantage pour notre application:
        - Am√©liore le contraste local m√™me avec √©clairage non uniforme
        - Fait ressortir les diff√©rences de couleur subtiles
        """
        # Convertir en espace LAB (L=luminance, A/B=chrominance)
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)

        # Appliquer CLAHE sur le canal L uniquement
        clahe = cv2.createCLAHE(clipLimit=clip_limit,
                                tileGridSize=(tile_size, tile_size))
        l_enhanced = clahe.apply(l)

        # Reconstruire l'image
        lab_enhanced = cv2.merge([l_enhanced, a, b])
        return cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    @staticmethod
    def gaussian_blur(image: np.ndarray, kernel_size: int = 3) -> np.ndarray:
        """
        Filtre gaussien: filtre passe-bas classique.

        Fonction de transfert (dans le domaine fr√©quentiel):
        H(u,v) = exp(-2œÄ¬≤œÉ¬≤(u¬≤+v¬≤))

        Effet: att√©nue les hautes fr√©quences (bruit) proportionnellement
        √† leur distance du centre fr√©quentiel.
        """
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)


# =============================================================================
# SECTION 4: OP√âRATIONS MORPHOLOGIQUES
# =============================================================================

class MorphologyOperations:
    """
    Op√©rations de morphologie math√©matique pour le nettoyage des masques.
    """

    @staticmethod
    def create_structuring_element(shape: int, size: Tuple[int, int]) -> np.ndarray:
        """
        Cr√©e un √©l√©ment structurant pour les op√©rations morphologiques.

        Types:
        - cv2.MORPH_RECT: rectangle (efficace pour bandes verticales)
        - cv2.MORPH_ELLIPSE: ellipse (pr√©serve mieux les formes arrondies)
        - cv2.MORPH_CROSS: croix
        """
        return cv2.getStructuringElement(shape, size)

    @staticmethod
    def opening(mask: np.ndarray, kernel: np.ndarray,
                iterations: int = 1) -> np.ndarray:
        """
        Ouverture morphologique: √ârosion suivie de Dilatation

        Effet: supprime les petits objets (bruit) tout en pr√©servant
        la forme g√©n√©rale des grands objets.

        Utilisation: nettoyer les fausses d√©tections de couleur
        """
        return cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=iterations)

    @staticmethod
    def closing(mask: np.ndarray, kernel: np.ndarray,
                iterations: int = 1) -> np.ndarray:
        """
        Fermeture morphologique: Dilatation suivie d'√ârosion

        Effet: remplit les petits trous et connecte les r√©gions proches.

        Utilisation: unifier les bandes de couleur fragment√©es
        """
        return cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=iterations)

    @staticmethod
    def clean_mask(mask: np.ndarray) -> np.ndarray:
        """
        Pipeline de nettoyage complet d'un masque binaire.

        √âtapes:
        1. Fermeture (combler les trous)
        2. Ouverture (supprimer le bruit)
        """
        # √âl√©ment structurant vertical (favorise les bandes verticales)
        kernel_vertical = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 5))

        # Fermeture pour combler les trous
        closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_vertical, iterations=2)

        # Ouverture pour supprimer le bruit
        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel_vertical, iterations=1)

        return opened


# =============================================================================
# SECTION 5: STABILISATION TEMPORELLE
# =============================================================================

class TemporalStabilizer:
    """
    Stabilise les lectures en faisant une moyenne temporelle.

    Justification technique:
    - Les d√©tections frame par frame peuvent √™tre bruit√©es
    - Une moyenne sur plusieurs frames donne un r√©sultat plus fiable
    - Impl√©ment√© comme un filtre moyenneur (moving average filter)
    """

    def __init__(self, history_size: int = 10):
        """
        Args:
            history_size: Nombre de lectures √† conserver pour la moyenne
        """
        self.history: deque = deque(maxlen=history_size)
        self.history_size = history_size

    def add_reading(self, reading: ResistanceReading):
        """Ajoute une nouvelle lecture √† l'historique"""
        self.history.append(reading)

    def get_stable_reading(self) -> Optional[ResistanceReading]:
        """
        Retourne la lecture la plus fr√©quente dans l'historique.

        Algorithme:
        1. Compter les occurrences de chaque valeur format√©e
        2. Retourner celle qui appara√Æt le plus souvent
        3. Minimum 3 lectures identiques pour validation
        """
        if len(self.history) < 3:
            return None

        # Compter les occurrences de chaque valeur
        value_counts: Dict[str, int] = {}
        value_readings: Dict[str, ResistanceReading] = {}

        for reading in self.history:
            key = reading.formatted_value
            value_counts[key] = value_counts.get(key, 0) + 1
            value_readings[key] = reading

        # Trouver la valeur la plus fr√©quente
        if value_counts:
            most_common = max(value_counts, key=value_counts.get)
            count = value_counts[most_common]

            # Minimum 3 lectures identiques pour validation
            if count >= 3:
                reading = value_readings[most_common]
                # Mettre √† jour la confiance bas√©e sur la stabilit√©
                stability = count / len(self.history)
                reading.confidence = min(1.0, reading.confidence * (0.5 + 0.5 * stability))
                return reading

        return None

    def clear(self):
        """Vide l'historique"""
        self.history.clear()


# =============================================================================
# SECTION 6: D√âTECTEUR DE BANDES
# =============================================================================

class BandDetector:
    """
    D√©tecte et analyse les bandes de couleur dans une r√©gion d'int√©r√™t.
    """

    def __init__(self):
        self.colors = HSVColorConfig.get_colors()
        self.morphology = MorphologyOperations()

    def detect_bands(self, roi_hsv: np.ndarray,
                     roi_bgr: np.ndarray) -> List[ColorBandInfo]:
        """
        D√©tecte toutes les bandes de couleur dans la ROI.

        Args:
            roi_hsv: ROI en espace HSV
            roi_bgr: ROI en espace BGR (pour debug)

        Returns:
            Liste des bandes d√©tect√©es, tri√©es par position X
        """
        detected_bands: List[ColorBandInfo] = []
        roi_h, roi_w = roi_hsv.shape[:2]

        # Cr√©er un masque pour isoler le corps de la r√©sistance
        # (exclure le fond blanc)
        white_mask = cv2.inRange(roi_hsv,
                                 np.array([0, 0, 210]),
                                 np.array([180, 35, 255]))
        resistor_mask = cv2.bitwise_not(white_mask)

        # Nettoyer le masque
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        resistor_mask = cv2.morphologyEx(resistor_mask, cv2.MORPH_CLOSE, kernel)
        resistor_mask = cv2.morphologyEx(resistor_mask, cv2.MORPH_OPEN, kernel)

        for color_name, (lower, upper, value) in self.colors.items():
            # Cr√©er le masque pour cette couleur
            lower_arr = np.array(lower)
            upper_arr = np.array(upper)
            color_mask = cv2.inRange(roi_hsv, lower_arr, upper_arr)

            # Appliquer le masque de la r√©sistance
            color_mask = cv2.bitwise_and(color_mask, resistor_mask)

            # Nettoyer le masque
            color_mask = self.morphology.clean_mask(color_mask)

            # Trouver les contours
            contours, _ = cv2.findContours(color_mask, cv2.RETR_EXTERNAL,
                                           cv2.CHAIN_APPROX_SIMPLE)

            for cnt in contours:
                area = cv2.contourArea(cnt)

                # Filtre minimum d'aire
                if area < 20:
                    continue

                x, y, w, h = cv2.boundingRect(cnt)

                # Crit√®res de forme pour une bande:
                # - Pas trop large (< 35% de la ROI)
                # - Assez haute (> 15% de la ROI)
                is_valid_width = w < roi_w * 0.35
                is_valid_height = h > roi_h * 0.15

                if is_valid_width and is_valid_height:
                    # Calculer le centre X
                    M = cv2.moments(cnt)
                    cx = int(M["m10"] / M["m00"]) if M["m00"] != 0 else x + w // 2

                    # V√©rifier que ce n'est pas un doublon
                    is_duplicate = any(abs(cx - b.x_position) < 12
                                       for b in detected_bands)

                    if not is_duplicate:
                        # Nettoyer le nom de la couleur
                        clean_name = color_name.replace('1', '').replace('2', '')

                        detected_bands.append(ColorBandInfo(
                            color_name=clean_name,
                            value=value,
                            x_position=cx,
                            area=area,
                            height=h,
                            width=w
                        ))

        # Trier par position X (gauche √† droite)
        detected_bands.sort(key=lambda b: b.x_position)

        return detected_bands


# =============================================================================
# SECTION 7: CALCULATEUR DE R√âSISTANCE
# =============================================================================

class ResistanceCalculator:
    """
    Calcule la valeur de r√©sistance √† partir des bandes d√©tect√©es.
    """

    TOLERANCE_MAP = {
        'marron': '¬±1%',
        'rouge': '¬±2%',
        'vert': '¬±0.5%',
        'bleu': '¬±0.25%',
        'violet': '¬±0.10%',
        'gris': '¬±0.05%',
        'or': '¬±5%',
        'argent': '¬±10%',
    }

    def correct_orientation(self, bands: List[ColorBandInfo]) -> List[ColorBandInfo]:
        """
        Corrige l'orientation si or/argent est au d√©but.

        Convention: la bande de tol√©rance (or/argent) est toujours √† la fin.
        """
        if len(bands) < 3:
            return bands

        first_val = bands[0].value
        last_val = bands[-1].value

        # Si or/argent au d√©but mais pas √† la fin -> inverser
        if first_val < 0 and last_val >= 0:
            return list(reversed(bands))

        return bands

    def calculate(self, bands: List[ColorBandInfo]) -> Optional[ResistanceReading]:
        """
        Calcule la valeur de r√©sistance.

        Format 4 bandes: Chiffre1, Chiffre2, Multiplicateur, Tol√©rance
        Format 5 bandes: Chiffre1, Chiffre2, Chiffre3, Multiplicateur, Tol√©rance
        """
        if len(bands) < 3:
            return None

        # Corriger l'orientation
        bands = self.correct_orientation(bands)

        try:
            tolerance = '¬±20%'

            # D√©terminer si on a une bande de tol√©rance
            if len(bands) >= 4 and bands[-1].value < 0:
                tolerance = self.TOLERANCE_MAP.get(bands[-1].color_name, '¬±5%')
                working_bands = bands[:-1]
            elif len(bands) >= 4 and bands[-1].color_name in self.TOLERANCE_MAP:
                tolerance = self.TOLERANCE_MAP[bands[-1].color_name]
                working_bands = bands[:-1]
            else:
                working_bands = bands[:3]

            # Valider que les premiers chiffres sont >= 0
            if working_bands[0].value < 0 or working_bands[1].value < 0:
                return None

            # Calculer la valeur
            if len(working_bands) >= 4:
                # 5 bandes: 3 chiffres significatifs
                if working_bands[2].value < 0:
                    return None
                digit1 = working_bands[0].value
                digit2 = working_bands[1].value
                digit3 = working_bands[2].value
                multiplier_val = working_bands[3].value
                base = digit1 * 100 + digit2 * 10 + digit3
            else:
                # 4 bandes: 2 chiffres significatifs
                digit1 = working_bands[0].value
                digit2 = working_bands[1].value
                multiplier_val = working_bands[2].value
                base = digit1 * 10 + digit2

            # Calculer le multiplicateur
            if multiplier_val >= 0:
                multiplier = 10 ** multiplier_val
            elif multiplier_val == -1:  # Or
                multiplier = 0.1
            elif multiplier_val == -2:  # Argent
                multiplier = 0.01
            else:
                return None

            resistance = base * multiplier

            # Formater la valeur
            if resistance >= 1_000_000:
                formatted = f"{resistance / 1_000_000:.2f} MŒ©"
            elif resistance >= 1_000:
                formatted = f"{resistance / 1_000:.2f} kŒ©"
            else:
                formatted = f"{resistance:.1f} Œ©"

            # Calculer la confiance
            confidence = min(1.0, len(bands) / 4.0 * 0.8)

            band_names = [b.color_name for b in bands]

            return ResistanceReading(
                value_ohms=resistance,
                formatted_value=formatted,
                tolerance=tolerance,
                bands=band_names,
                confidence=confidence,
                timestamp=time.time()
            )

        except (IndexError, ValueError, TypeError) as e:
            return None


# =============================================================================
# SECTION 8: ANALYSEUR TEMPS R√âEL
# =============================================================================

class RealtimeResistanceAnalyzer:
    """
    Analyseur temps r√©el de r√©sistances via webcam.

    Pipeline:
    1. Capture frame
    2. Pr√©traitement (filtrage bilat√©ral, CLAHE)
    3. Extraction ROI
    4. D√©tection des bandes
    5. Calcul de la valeur
    6. Stabilisation temporelle
    7. Affichage
    """

    def __init__(self, camera_id: int = 0,
                 roi_width: int = 400, roi_height: int = 120):
        """
        Args:
            camera_id: ID de la cam√©ra (0 = webcam par d√©faut, ou iVCam)
            roi_width: Largeur de la zone de scan
            roi_height: Hauteur de la zone de scan
        """
        self.camera_id = camera_id
        self.roi_size = (roi_width, roi_height)

        self.filters = SignalFilters()
        self.band_detector = BandDetector()
        self.calculator = ResistanceCalculator()
        self.stabilizer = TemporalStabilizer(history_size=15)

        self.cap = None
        self.is_running = False

    def preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        Applique le pipeline de pr√©traitement.

        Ordre des op√©rations:
        1. Filtre gaussien l√©ger (r√©duction du bruit HF)
        2. CLAHE (am√©lioration du contraste)
        3. Filtre bilat√©ral (lissage + pr√©servation des bords)
        """
        # √âtape 1: Filtre gaussien l√©ger
        denoised = self.filters.gaussian_blur(frame, kernel_size=3)

        # √âtape 2: CLAHE pour am√©liorer le contraste
        enhanced = self.filters.clahe_enhancement(denoised, clip_limit=2.5)

        # √âtape 3: Filtre bilat√©ral
        filtered = self.filters.bilateral_filter(enhanced, d=7,
                                                 sigma_color=50,
                                                 sigma_space=50)

        return filtered

    def extract_roi(self, frame: np.ndarray) -> Tuple[np.ndarray, Tuple[int, int, int, int]]:
        """
        Extrait la r√©gion d'int√©r√™t au centre de l'image.

        Returns:
            (roi, (x1, y1, x2, y2))
        """
        h, w = frame.shape[:2]
        roi_w, roi_h = self.roi_size

        x1 = (w - roi_w) // 2
        y1 = (h - roi_h) // 2
        x2 = x1 + roi_w
        y2 = y1 + roi_h

        roi = frame[y1:y2, x1:x2].copy()

        return roi, (x1, y1, x2, y2)

    def analyze_frame(self, frame: np.ndarray) -> Optional[ResistanceReading]:
        """
        Analyse une frame et retourne la lecture de r√©sistance.
        """
        # Pr√©traitement
        preprocessed = self.preprocess_frame(frame)

        # Extraire la ROI
        roi, roi_coords = self.extract_roi(preprocessed)

        # Convertir en HSV
        roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

        # D√©tecter les bandes
        bands = self.band_detector.detect_bands(roi_hsv, roi)

        if len(bands) >= 3:
            # Calculer la valeur
            reading = self.calculator.calculate(bands)

            if reading:
                # Ajouter √† la stabilisation
                self.stabilizer.add_reading(reading)
                return reading

        return None

    def draw_ui(self, frame: np.ndarray,
                roi_coords: Tuple[int, int, int, int],
                reading: Optional[ResistanceReading],
                stable_reading: Optional[ResistanceReading],
                fps: float):
        """
        Dessine l'interface utilisateur sur la frame.
        """
        x1, y1, x2, y2 = roi_coords

        # Dessiner le rectangle de la ROI
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)

        # Instruction
        cv2.putText(frame, "Placez la resistance ici (fond uni)",
                    (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                    0.5, (0, 255, 255), 1)

        # Zone d'affichage du r√©sultat
        result_y = y2 + 15
        cv2.rectangle(frame, (x1, result_y), (x2, result_y + 55), (0, 0, 0), -1)

        # Afficher le r√©sultat
        if stable_reading:
            color = (0, 255, 0)  # Vert = stable
            text = f"Valeur: {stable_reading.formatted_value} {stable_reading.tolerance}"
            bands_text = " ‚Üí ".join(stable_reading.bands)
        elif reading:
            color = (0, 255, 255)  # Jaune = en cours
            text = f"Detection: {reading.formatted_value}"
            bands_text = " ‚Üí ".join(reading.bands)
        else:
            color = (0, 0, 255)  # Rouge = pas de d√©tection
            text = "Valeur: En attente..."
            bands_text = ""

        cv2.putText(frame, text, (x1 + 5, result_y + 25),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

        if bands_text:
            cv2.putText(frame, f"Bandes: {bands_text}", (x1 + 5, result_y + 50),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

        # Afficher les FPS
        cv2.putText(frame, f"FPS: {fps:.1f}", (10, 25),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # Instructions
        cv2.putText(frame, "Q: Quitter | R: Reset | C: Calibrer",
                    (10, frame.shape[0] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)

        return frame

    def run(self):
        """
        Lance l'analyseur en temps r√©el.
        """
        print("\n" + "=" * 60)
        print("    ANALYSEUR DE R√âSISTANCES EN TEMPS R√âEL")
        print("    Projet de Traitement de Signal - EPHEC 2025")
        print("=" * 60)
        print("\nD√©marrage de la cam√©ra...")

        # Ouvrir la cam√©ra
        self.cap = cv2.VideoCapture(self.camera_id)

        if not self.cap.isOpened():
            print(f"‚ùå Erreur: Impossible d'ouvrir la cam√©ra {self.camera_id}")
            print("   Essayez avec un autre ID (1, 2, ...)")
            return

        print(f"‚úì Cam√©ra {self.camera_id} ouverte")
        print("\nCommandes:")
        print("  Q ou ESC: Quitter")
        print("  R: R√©initialiser la stabilisation")
        print("  C: Afficher les infos de calibration")
        print("=" * 60)

        self.is_running = True
        frame_times = deque(maxlen=30)

        try:
            while self.is_running:
                start_time = time.time()

                # Capturer une frame
                ret, frame = self.cap.read()
                if not ret:
                    print("‚ö†Ô∏è Erreur de lecture de la cam√©ra")
                    break

                # Analyser la frame
                reading = self.analyze_frame(frame)
                stable_reading = self.stabilizer.get_stable_reading()

                # Calculer les FPS
                frame_time = time.time() - start_time
                frame_times.append(frame_time)
                fps = 1.0 / (sum(frame_times) / len(frame_times)) if frame_times else 0

                # Extraire les coordonn√©es de la ROI pour l'affichage
                _, roi_coords = self.extract_roi(frame)

                # Dessiner l'interface
                display_frame = self.draw_ui(frame, roi_coords,
                                             reading, stable_reading, fps)

                # Afficher
                cv2.imshow('Analyseur de Resistances', display_frame)

                # G√©rer les touches
                key = cv2.waitKey(1) & 0xFF

                if key == ord('q') or key == 27:  # Q ou ESC
                    break
                elif key == ord('r'):  # R = Reset
                    self.stabilizer.clear()
                    print("üîÑ Stabilisation r√©initialis√©e")
                elif key == ord('c'):  # C = Calibration info
                    self._print_calibration_info()

                # V√©rifier le crit√®re de temps < 1s
                if frame_time > 1.0:
                    print(f"‚ö†Ô∏è Temps de traitement √©lev√©: {frame_time * 1000:.0f}ms")

        finally:
            self.cap.release()
            cv2.destroyAllWindows()
            print("\n‚úì Analyse termin√©e")

    def _print_calibration_info(self):
        """Affiche les informations de calibration des couleurs."""
        print("\nüìä Plages HSV des couleurs:")
        print("-" * 50)
        for name, (lower, upper, val) in HSVColorConfig.get_colors().items():
            print(f"  {name:10s}: H=[{lower[0]:3d}-{upper[0]:3d}], "
                  f"S=[{lower[1]:3d}-{upper[1]:3d}], "
                  f"V=[{lower[2]:3d}-{upper[2]:3d}] -> {val}")
        print("-" * 50)


def find_available_cameras(max_cameras: int = 10) -> List[Tuple[int, str]]:
    """
    Recherche toutes les cam√©ras disponibles sur le syst√®me.
    Utile pour trouver iVCam, DroidCam, etc.

    Returns:
        Liste de tuples (id, description)
    """
    available = []

    for i in range(max_cameras):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            # Essayer de lire une frame pour v√©rifier
            ret, _ = cap.read()
            if ret:
                # Obtenir la r√©solution
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                available.append((i, f"Camera {i} ({width}x{height})"))
            cap.release()

    return available


def select_camera() -> int:
    """
    Affiche les cam√©ras disponibles et permet √† l'utilisateur de choisir.

    Returns:
        ID de la cam√©ra s√©lectionn√©e
    """
    print("\nüîç Recherche des cam√©ras disponibles...")
    cameras = find_available_cameras()

    if not cameras:
        print("‚ùå Aucune cam√©ra trouv√©e!")
        return 0

    print(f"\nüì∑ {len(cameras)} cam√©ra(s) trouv√©e(s):")
    for cam_id, desc in cameras:
        print(f"   [{cam_id}] {desc}")

    if len(cameras) == 1:
        print(f"\n‚Üí Utilisation de la cam√©ra {cameras[0][0]}")
        return cameras[0][0]

    # Si plusieurs cam√©ras, demander √† l'utilisateur
    print("\nüí° Conseil: Si iVCam ne fonctionne pas avec l'ID 0,")
    print("   essayez un autre num√©ro (souvent 1 ou 2 pour les cam√©ras virtuelles)")

    while True:
        try:
            choice = input(f"\nEntrez le num√©ro de cam√©ra (0-{len(cameras) - 1}, ou 'a' pour auto): ").strip()
            if choice.lower() == 'a':
                # Auto: prendre la cam√©ra avec la plus haute r√©solution (souvent iVCam)
                best = max(cameras, key=lambda x: int(x[1].split('(')[1].split('x')[0]))
                print(f"‚Üí S√©lection automatique: {best[1]}")
                return best[0]
            else:
                cam_id = int(choice)
                if any(c[0] == cam_id for c in cameras):
                    return cam_id
                print("‚ö†Ô∏è Num√©ro invalide, r√©essayez.")
        except ValueError:
            print("‚ö†Ô∏è Entrez un num√©ro valide.")
        except KeyboardInterrupt:
            return cameras[0][0]


# =============================================================================
# SECTION 9: POINT D'ENTR√âE
# =============================================================================

def main():
    """Point d'entr√©e principal."""
    import argparse

    parser = argparse.ArgumentParser(
        description='Analyseur de r√©sistances en temps r√©el'
    )
    parser.add_argument('-c', '--camera', type=int, default=-1,
                        help='ID de la cam√©ra (-1 = s√©lection interactive)')
    parser.add_argument('-w', '--width', type=int, default=400,
                        help='Largeur de la zone de scan (d√©faut: 400)')
    parser.add_argument('-H', '--height', type=int, default=120,
                        help='Hauteur de la zone de scan (d√©faut: 120)')
    parser.add_argument('-l', '--list', action='store_true',
                        help='Lister les cam√©ras disponibles et quitter')

    args = parser.parse_args()

    # Si demande de liste des cam√©ras
    if args.list:
        print("\nüîç Recherche des cam√©ras disponibles...")
        cameras = find_available_cameras()
        if cameras:
            print(f"\nüì∑ {len(cameras)} cam√©ra(s) trouv√©e(s):")
            for cam_id, desc in cameras:
                print(f"   [{cam_id}] {desc}")
            print("\nüí° Pour utiliser iVCam, lancez l'app sur votre t√©l√©phone")
            print("   puis relancez ce script. iVCam aura souvent l'ID 1 ou 2.")
        else:
            print("‚ùå Aucune cam√©ra trouv√©e!")
        return

    # S√©lection de la cam√©ra
    if args.camera == -1:
        camera_id = select_camera()
    else:
        camera_id = args.camera

    # Cr√©er et lancer l'analyseur
    analyzer = RealtimeResistanceAnalyzer(
        camera_id=camera_id,
        roi_width=args.width,
        roi_height=args.height
    )

    analyzer.run()


if __name__ == "__main__":
    main()